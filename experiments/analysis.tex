\documentclass[a4paper,10pt]{article}
\usepackage{graphicx}
%\usepackage{lscape}
\title{Analysis of various machine learning algorithms through both their learning phase and testing phase.}
\author{Shalimar Lake, Kyle C. Blyth}
\date{December 6, 2016}
\begin{document}
%\begin{landscape}
\pagestyle{empty}
\maketitle
\thispagestyle{empty}

\pagebreak

\section{Training Phase}

\subsection {Algorithm Accuracy}
\begin {table}[!htp]
\caption {Accuracy During Training of the Algorithms}
\centering
\begin{tiny}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
Data sets&AdaBoost.NC-C&C45-C&Ripper-C&SIA-C&GFS-GCCL-C&Chi-RW-C&iRProp+-c\\\hline
bupa&0.8888712948&0.8588887296&0.8595852374&1.0&0.5999858288&0.5987037249&0.735583307\\
cleveland&0.6520983632&0.8305207032&0.8200435419&1.0&0.5667956505&0.9139676423&0.6681685244\\
glass&0.6661449733&0.9371804036&0.9077588163&1.0&0.6854301106&0.659897225&0.6000364304\\
haberman&0.7941396574&0.7585177866&0.5689459816&0.974944664&0.7385638999&0.7425546772&0.7723227931\\
iris&0.6666666667&0.98&0.9466666667&1.0&0.9577777778&0.9377777778&0.9762962963\\
monk2&1.0&1.0&1.0&0.6127404703&0.9722272853&0.9724856798&0.9794045317\\
new-thyroid&0.8599487207&0.9844986913&0.9927648096&1.0&0.8749452487&0.8594359276&0.9312643555\\
pima&0.9186947065&0.8381056819&0.8504096379&1.0&0.6976281338&0.7521719218&0.7748853005\\
vehicle&0.4841081461.0&0.9055718232&0.8794465081.0&1.0&0.6201682411.0&0.6591842823&0.7407407024\\
wine&0.7297166149&0.988761646&0.998136646&1.0&0.9769060559&0.988140528&1\\
wisconsin&0.9907306085&0.9812959722&0.9837358005&0.9985347264&0.9762505403&0.9803187761.0&0.9816187955\\
\hline
\end{tabular}
\end{tiny}
\end{table}
\flushleft
\subsection {Ranking}
Average ranks obtained by applying the Friedman procedure to the accuracy reported by each of the algorithms during their training phase.

\begin{table}[!htp]
\caption{Average Rankings of the algorithms}
\centering
\begin{tabular}{|c|c|}\hline
Algorithm&Ranking\\\hline
AdaBoost.NC-C & 4.3636\\
C45-C & 3.1818\\
Ripper-C & 3.4545\\
SIA-C & 1.5909\\
GFS-GCCL-C & 5.8182\\
Chi-RW-C & 5.4545\\
iRProp+-c & 4.1364\\
\hline
\end{tabular}
\end{table}
\flushleft
P-value computed by Friedman Test: 5.8390905970928664E-5.\newline

\pagebreak

\subsection{Adjusted p-values}

\begin{table}[!htp]
\scriptsize\centering
\caption{Adjusted $p$-values}
\begin{tabular}{ccccc}
i&hypothesis&unadjusted $p$&$p_{Holm}$&$p_{Shaf}$\\
\hline1&SIA-C vs .GFS-GCCL-C&0.000004&0.000093&0.000093\\
2&SIA-C vs .Chi-RW-C&0.000027&0.000547&0.00041\\
3&AdaBoost.NC-C vs .SIA-C&0.002611&0.049616&0.039171\\
4&C45-C vs .GFS-GCCL-C&0.004209&0.075754&0.063129\\
5&SIA-C vs .iRProp+-c&0.00572&0.097245&0.085805\\
6&Ripper-C vs .GFS-GCCL-C&0.010288&0.164601&0.154313\\
7&C45-C vs .Chi-RW-C&0.013613&0.204194&0.204194\\
8&Ripper-C vs .Chi-RW-C&0.029913&0.418782&0.329043\\
9&Ripper-C vs .SIA-C&0.043052&0.559681&0.473576\\
10&GFS-GCCL-C vs .iRProp+-c&0.067878&0.814536&0.746658\\
11&C45-C vs .SIA-C&0.084146&0.925601&0.925601\\
12&AdaBoost.NC-C vs .GFS-GCCL-C&0.114317&1.143168&1.143168\\
13&Chi-RW-C vs .iRProp+-c&0.152417&1.371756&1.371756\\
14&AdaBoost.NC-C vs .C45-C&0.19949&1.59592&1.39643\\
15&AdaBoost.NC-C vs .Chi-RW-C&0.236289&1.654024&1.654024\\
16&C45-C vs .iRProp+-c&0.300074&1.800446&1.800446\\
17&AdaBoost.NC-C vs .Ripper-C&0.323678&1.800446&1.800446\\
18&Ripper-C vs .iRProp+-c&0.459181&1.836725&1.836725\\
19&GFS-GCCL-C vs .Chi-RW-C&0.693012&2.079036&2.079036\\
20&C45-C vs .Ripper-C&0.76717&2.079036&2.079036\\
21&AdaBoost.NC-C vs .iRProp+-c&0.805116&2.079036&2.079036\\
\hline
\end{tabular}
\end{table}
\flushleft
\pagebreak



\section{Testing Phase}

\subsection {Algorithm Accuracy}
\begin {table}[!htp]
\caption {Accuracy During Testing of the Algorithms}
\centering
\begin{tiny}
\begin{tabular}{|c|c|c|c|c|c|c|c|}\hline
Data sets&AdaBoost.NC-C&C45-C&Ripper-C&SIA-C&GFS-GCCL-C&Chi-RW-C&iRProp+-c\\\hline
bupa&0.7021252372&0.6699918677&0.5932095419&0.6295066414&0.5846381133&0.5787232312&0.713185145\\
cleveland&0.5087549658&0.5248379151.0&0.4215750305&0.5257746703&0.5288789131.0&0.3802621961.0&0.580374755\\
glass&0.5493051634&0.6744271912&0.6629650543&0.7186046803&0.6320572181.0&0.6004121965&0.5820380827\\
haberman&0.7248387097&0.7316129032&0.467311828&0.6697849462&0.7320430108&0.7319354839&0.7577419355\\
iris&0.66&0.96&0.9466666667&0.96&0.9533333333&0.9266666667&0.9533333333\\
monk2&1.0&1.0&1.0&0.6251557806&0.9726744186&0.4289223323&0.9704016913\\
new-thyroid&0.8188311688&0.9398268398&0.9257575758&0.9491341991.0&0.8612554113&0.8424242424&0.9396103896\\
pima&0.741069895&0.7423173318&0.7083981808&0.716274515&0.6823189968&0.7305773174&0.7656794959\\
vehicle&0.4562184874&0.7469187675&0.6866806723&0.5969327731.0&0.5722689076&0.6077310924&0.7305182073\\
wine&0.7137254902&0.9490196078&0.9320261438&0.9437908497&0.910130719&0.9382352941.0&0.9774509804\\
wisconsin&0.9768492939&0.9562572397&0.959089887&0.9679799288&0.9708791719&0.9125118784&0.9708364627\\
\hline
\end{tabular}
\end{tiny}
\end{table}
\flushleft
\subsection {Ranking}
Average ranks obtained by applying the Friedman procedure to the accuracy reported by each of the algorithms during their testing phase.

\begin{table}[!htp]
\caption{Average Rankings of the Algorithms}
\centering
\begin{tabular}{|c|c|}\hline
Algorithm&Ranking\\\hline
AdaBoost.NC-C & 4.8182\\
C45-C & 2.6818\\
Ripper-C & 4.6364\\
SIA-C & 3.5909\\
GFS-GCCL-C & 4.3182\\
Chi-RW-C & 5.4545\\
iRProp+-c & 2.5\\
\hline
\end{tabular}
\end{table}
\flushleft
P-value computed by Friedman Test: 0.007455103063423896.\newline

\pagebreak

\subsection{Adjusted p-values}

\begin{table}[!htp]
\scriptsize\centering
\caption{Adjusted $p$-values}
\begin{tabular}{ccccc}
i&hypothesis&unadjusted $p$&$p_{Holm}$&$p_{Shaf}$\\
\hline1&Chi-RW-C vs .iRProp+-c&0.001339&0.028116&0.028116\\
2&C45-C vs .Chi-RW-C&0.002611&0.052227&0.039171\\
3&AdaBoost.NC-C vs .iRProp+-c&0.011847&0.225096&0.177707\\
4&AdaBoost.NC-C vs .C45-C&0.02038&0.366838&0.305698\\
5&Ripper-C vs .iRProp+-c&0.02038&0.366838&0.305698\\
6&C45-C vs .Ripper-C&0.033847&0.541546&0.507699\\
7&SIA-C vs .Chi-RW-C&0.043052&0.645786&0.645786\\
8&GFS-GCCL-C vs .iRProp+-c&0.048398&0.677575&0.645786\\
9&C45-C vs .GFS-GCCL-C&0.075656&0.983522&0.832211\\
10&AdaBoost.NC-C vs .SIA-C&0.182744&2.192934&2.010189\\
11&GFS-GCCL-C vs .Chi-RW-C&0.21733&2.390628&2.390628\\
12&SIA-C vs .iRProp+-c&0.236289&2.390628&2.390628\\
13&Ripper-C vs .SIA-C&0.256389&2.390628&2.390628\\
14&C45-C vs .SIA-C&0.323678&2.589425&2.390628\\
15&Ripper-C vs .Chi-RW-C&0.374414&2.620901&2.620901\\
16&SIA-C vs .GFS-GCCL-C&0.429795&2.620901&2.620901\\
17&AdaBoost.NC-C vs .Chi-RW-C&0.48966&2.620901&2.620901\\
18&AdaBoost.NC-C vs .GFS-GCCL-C&0.587261&2.620901&2.620901\\
19&Ripper-C vs .GFS-GCCL-C&0.729775&2.620901&2.620901\\
20&AdaBoost.NC-C vs .Ripper-C&0.843526&2.620901&2.620901\\
21&C45-C vs .iRProp+-c&0.843526&2.620901&2.620901\\
\hline
\end{tabular}
\end{table}
\flushleft

\section {Analysis}
It's pretty clear to us that AdaBoost.NC-C, C45-C, and .GFS-GCCL-C are among the top performers for these algorithms, easily outperforming their competition. Also to note that while during the training phase Ripper-C was a little bit lower on the chain, it performed much better during the testing phase. The Chi-RW-C algorithm seems to have experienced the opposite, with its accuracy decreasing as it left the training phase.

%\end{landscape}
\end{document}